{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T10:48:26.913528Z",
     "start_time": "2024-11-27T10:48:22.216282Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\stock_sentiment_predictor\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 다양한 주체가 있는 문장을 추가적으로 Fine-tuning시키기\n",
    "\n",
    "- 뉴스 감정 예측 모델의 성능을 향상시키기 위해, **다양한 주체**가 포함된 애매한 문장을 추가적으로 학습하는 Fine-tuning을 진행\n",
    "- Fine-tuning 이전에는 아래와 같은 문장에서 감정 예측 성능이 부족했으며, 이를 보완하기 위해 학습 데이터에서 **다양한 주체가 포함된 문장**들을 선별하여 Fine-tuning 데이터셋을 생성\n",
    "- 하지만 선별된 데이터의 양이 적어 학습에 적합하지 않았기 때문에, **K-TACC**를 사용하여 데이터 증강을 진행\n",
    "\n",
    "---\n",
    "\n",
    "### Fine-tuning 이전 성능\n",
    "\n",
    "| 문장                                                                         | 실제 감정 | 예측 감정 |\n",
    "|----------------------------------------------------------------------------|-------|-------|\n",
    "| 삼성전자가 실적 발표에서 긍정적인 결과를 보였으나, SK하이닉스는 부진했다...                               | 부정    | 중립    |\n",
    "| SK하이닉스는 실적 상승을 기록했지만 삼성전자는 다소 실망스러운 실적을 발표했다...                            | 긍정    | 부정    |\n",
    "| SK하이닉스의 실적 발표 발표에서 클라우드 부문의 성장 둔화가 우려를 불러일으켰다, 아마존는 반도체 부문 시장에서 강세를 보였다... | 부정    | 긍정    |\n",
    "\n",
    "---\n",
    "\n",
    "### Fine-tuning 이후 성능\n",
    "\n",
    "| 문장                                                                         | 실제 감정 | 예측 감정 |\n",
    "|----------------------------------------------------------------------------|-------|-------|\n",
    "| 삼성전자가 실적 발표에서 긍정적인 결과를 보였으나, SK하이닉스는 부진했다...                               | 부정    | 부정    |\n",
    "| SK하이닉스는 실적 상승을 기록했지만 삼성전자는 다소 실망스러운 실적을 발표했다...                            | 긍정    | 긍정    |\n",
    "| SK하이닉스의 실적 발표 발표에서 클라우드 부문의 성장 둔화가 우려를 불러일으켰다, 아마존는 반도체 부문 시장에서 강세를 보였다... | 부정    | 부정    |\n",
    "\n",
    "---\n",
    "\n",
    "Fine-tuning을 통해 애매한 주체가 포함된 문장에서도 모델의 감정 예측 성능 개선\n"
   ],
   "id": "436122f2a21971d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T10:48:29.746087Z",
     "start_time": "2024-11-27T10:48:26.933726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 경로와 토크나이저 경로 설정\n",
    "MODEL_PATH = \"../sentiment_analysis_model\"  # 모델이 저장된 경로\n",
    "MODEL_NAME = \"klue/bert-base\"  # 모델 이름\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = TFBertForSequenceClassification.from_pretrained(MODEL_PATH)"
   ],
   "id": "c40048694b20de02",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../sentiment_analysis_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T10:48:29.841001Z",
     "start_time": "2024-11-27T10:48:29.827039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 다양한 주체가 있는 데이터 불러오기\n",
    "dataset = pd.read_csv(\"../data/augmented_subject_focus_data.csv\", encoding=\"utf-8\", header=None, names=['description', 'sentiment'])"
   ],
   "id": "8c686324108b46c6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T10:48:30.118288Z",
     "start_time": "2024-11-27T10:48:29.861946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터 셋 요약 확인\n",
    "print('데이터 요약')\n",
    "dataset.info()\n",
    "\n",
    "# 'description' 컬럼을 문자열 형식으로 변환\n",
    "dataset['description'] = dataset['description'].astype(str)\n",
    "\n",
    "# 데이터 셔플\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 셔플 된 데이터 확인\n",
    "print(dataset.head())\n",
    "\n",
    "# 데이터 전처리\n",
    "def encode_data(data):\n",
    "    return tokenizer(\n",
    "        data['description'].tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 전처리\n",
    "train_encodings = encode_data(train_data)\n",
    "val_encodings = encode_data(val_data)"
   ],
   "id": "32e42dc43de6cd09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 요약\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 537 entries, 0 to 536\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   description  537 non-null    object\n",
      " 1   sentiment    537 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.5+ KB\n",
      "                                         description  sentiment\n",
      "0  삼성전자는 실적 부진에도 불구하고 금리 추가 인하 기대감으로 상승했지만 SK하이닉스...          0\n",
      "1  반면 아마존은 글로벌 경제 불확실성 속에서도 전과 다름없이 긍정적인 실적을 기록했지...          0\n",
      "2  삼성전자는 부진했지만 같은 52시간 규제안 속에서도 SK하이닉스는 최고의 실적을 냈...          2\n",
      "3  삼성전자의 경우 HBM 분야의 기술 경쟁력이 뒤쳐진 상태이기에 범용 메모리반도체 시...          2\n",
      "4  중국의 반도체 창신메모리CXMT는 D램 생산 기술 분야에서 삼성전자와 SK하이닉스 ...          0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T10:50:35.916928Z",
     "start_time": "2024-11-27T10:48:30.190068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 감정 레이블\n",
    "train_labels = train_data['sentiment'].values\n",
    "val_labels = val_data['sentiment'].values\n",
    "\n",
    "# TensorFlow Dataset 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings), train_labels\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings), val_labels\n",
    "))\n",
    "\n",
    "# 배치 처리 및 데이터 셔플\n",
    "train_dataset = train_dataset.shuffle(len(train_data)).batch(16)\n",
    "val_dataset = val_dataset.batch(16)\n",
    "\n",
    "# 콜백 함수 정의 (EarlyStopping)\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.001, patience=2),\n",
    "]\n",
    "\n",
    "# 모델 학습 준비 (Adam 옵티마이저, 손실 함수 설정)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=callbacks)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "model.save_pretrained('../subject_focus_finetuned_model')\n",
    "tokenizer.save_pretrained(\"../subject_focus_finetuned_model\")"
   ],
   "id": "e64e0402223b7aa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 33s 500ms/step - loss: 1.5113 - accuracy: 0.5175 - val_loss: 0.7585 - val_accuracy: 0.6389\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 10s 372ms/step - loss: 0.7629 - accuracy: 0.6550 - val_loss: 0.5351 - val_accuracy: 0.7685\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 10s 373ms/step - loss: 0.5607 - accuracy: 0.7855 - val_loss: 0.3828 - val_accuracy: 0.8796\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 10s 379ms/step - loss: 0.3903 - accuracy: 0.8625 - val_loss: 0.3121 - val_accuracy: 0.9259\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 10s 374ms/step - loss: 0.2819 - accuracy: 0.9138 - val_loss: 0.2632 - val_accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 10s 377ms/step - loss: 0.2114 - accuracy: 0.9394 - val_loss: 0.2003 - val_accuracy: 0.9537\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 10s 373ms/step - loss: 0.1622 - accuracy: 0.9510 - val_loss: 0.1448 - val_accuracy: 0.9444\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 10s 376ms/step - loss: 0.1456 - accuracy: 0.9604 - val_loss: 0.1036 - val_accuracy: 0.9630\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 10s 378ms/step - loss: 0.0928 - accuracy: 0.9720 - val_loss: 0.0548 - val_accuracy: 0.9815\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 10s 382ms/step - loss: 0.0570 - accuracy: 0.9860 - val_loss: 0.0234 - val_accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../subject_focus_finetuned_model\\\\tokenizer_config.json',\n",
       " '../subject_focus_finetuned_model\\\\special_tokens_map.json',\n",
       " '../subject_focus_finetuned_model\\\\vocab.txt',\n",
       " '../subject_focus_finetuned_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
